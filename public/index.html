<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title> | MAGGIE AI companion Experiment</title>
  <meta name="description"
    content=" â€” MAGGIE (Memory-Augmented Graph-Guided Intelligent Entity) Liaison experiment with MemoryKeep (Powered by Gemma 3).">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400..900;1,400..900&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap"
    rel="stylesheet">
  <link rel="stylesheet" href="index.css">
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
</head>

<body>

  <!-- â•â•â• SIDEBAR â•â•â• -->
  <div class="sidebar">
    <div class="logo">
      <span class="icon">âœ¨</span> MAGGIE
    </div>

    <!-- MAIN NAV -->
    <nav class="sidebar-nav">
      <a href="index.html" class="nav-item active">Neural Bridge</a>
      <a href="library.html" class="nav-item">The Library</a>
    </nav>

    <!-- Sidebar Persona Image - Best with 150x500 aspect -->
    <div class="sidebar-persona">
      <!-- Image should be 500-550px tall, to be updated by user -->
      <img id="sidebar-img" src="images/MAGGIE.png" alt="MAGGIE">
    </div>

    <div class="sidebar-body">
      <!-- Neural Metrics -->
      <div class="widget">
        <div class="widget-title">Neural Metrics</div>
        <div class="metric-card">
          <div class="metric-mini">
            <div id="exp-val" class="metric-value">0</div>
            <div class="metric-label">Experiences</div>
          </div>
          <div class="metric-mini">
            <div id="dom-val" class="metric-value">0</div>
            <div class="metric-label">Domain</div>
          </div>
          <div class="metric-mini">
            <div id="graph-nodes-val" class="metric-value" style="color: var(--neon-cyan)">0</div>
            <div class="metric-label">Nodes</div>
          </div>
          <div class="metric-mini">
            <div id="graph-edges-val" class="metric-value" style="color: var(--neon-orange)">0</div>
            <div class="metric-label">Edges</div>
          </div>
        </div>

        <!-- Context Gauge -->
        <div class="context-gauge">
          <div class="gauge-header">
            <span class="gauge-label">Stream Context</span>
            <span class="gauge-value" id="ctx-pct">0%</span>
          </div>
          <div class="gauge-bar">
            <div class="gauge-fill" id="ctx-fill" style="width: 0%"></div>
          </div>
        </div>
      </div>

      <!-- Sifter Reports -->
      <div class="widget">
        <div class="widget-title">Sleep Cycle Reports (The Sifter)</div>
        <div class="report-card" id="reports">
          <div class="report-empty">Awaiting first sleep simulation...</div>
        </div>
      </div>

      <!-- Intake Valve -->
      <div class="widget">
        <div class="widget-title">Intake Valve (Live)</div>
        <div id="activity" class="activity-feed">
          <div class="activity-line">Core protocols loaded.</div>
        </div>
      </div>

      <!-- Knowledge Graph -->
      <div class="widget">
        <div class="widget-title">Knowledge Graph</div>
        <div class="graph-panel" id="graph-panel">
          <div id="graph-nodes-display" class="graph-node-list"></div>
          <div id="graph-edges-display"></div>
          <div class="graph-empty" id="graph-empty">Graph builds as you talk...</div>
        </div>
      </div>

      <!-- Task Tracker -->
      <div class="widget">
        <div class="widget-title">Task Tracker</div>
        <div class="task-stats" id="task-stats"></div>
        <div class="task-list" id="task-list">
          <div class="task-empty">No tasks yet. Ask to create one.</div>
        </div>
      </div>

      <!-- Keep in Touch -->
      <div class="widget">
        <div class="widget-title">Keep in Touch</div>
        <div class="email-collect-card">
          <input type="text" id="collect-name" placeholder="Name">
          <input type="email" id="collect-email" placeholder="Email" required>
          <button onclick="submitEmail()" class="action-btn" style="width:100%; margin-top:10px;">Connect</button>
          <div id="collect-status" style="font-size: 0.7rem; margin-top: 8px; text-align: center; display: none;"></div>
        </div>
      </div>
    </div>

    <div class="sidebar-footer">
      USER: JEWELLS | <span class="neural-pulse"></span>SESSION STABLE
    </div>
  </div>

  <!-- â•â•â• MAIN CONTENT â•â•â• -->
  <div class="main-content">
    <div class="header">
      <div class="header-label">
        PROTOCOL: <span class="active">NEURAL-KEEP (AGENTIC)</span> Â· MAGGIE ENGINE
      </div>
      <div class="header-actions">
        <button id="metrics-btn" class="action-btn" onclick="toggleMetrics()" title="Neural Metrics">ğŸ§  STATS</button>
        <button id="tts-toggle" onclick="toggleTTS()" class="action-btn" title="Toggle Voice">ğŸ”ˆ ON</button>
        <button onclick="copyHistory()" class="action-btn">COPY LOGS</button>

      </div>
    </div>

    <!-- Metrics Overlay (for Widget Mode) -->
    <div id="metrics-overlay" class="metrics-overlay">
      <div class="metrics-header">
        <span>NEURAL STATUS</span>
        <button onclick="toggleMetrics()">âœ•</button>
      </div>
      <div id="metrics-content">
        <!-- Cloned from sidebar widgets via JS -->
      </div>

    </div>

    <div id="chat-container">
      <div class="message system-note">MAGGIE Neural Bridge Connected. MemoryKeep v3 + Graph + Vision + Email + Browser
        +
        Telegram Active. 11 agentic tools online. Heartbeat engaged.</div>
    </div>

    <div class="input-wrapper">
      <div class="input-container">
        <input id="image-upload" type="file" accept="image/*" style="display:none" onchange="handleImageSelect(event)">
        <button class="upload-btn" onclick="document.getElementById('image-upload').click()"
          title="Upload image for vision">ğŸ“·</button>
        <button id="mic-btn" class="mic-btn" onclick="toggleMic()" title="Speech-to-text">ğŸ™ï¸</button>
        <input id="user-input" type="text" placeholder="Transceive input..." autocomplete="off">
        <button id="send-btn" onclick="handleSend()" class="send-btn">SEND</button>
      </div>
      <div id="image-preview-container" style="padding: 0 4px;"></div>
      <div class="input-footer">
        <span>MAGGIE Â· Memory-Augmented Graph-Guided Intelligent Entity</span>
        <span id="footer-status">Ready</span>
      </div>
    </div>
  </div>

  <script>
    const API = '';
    let isProcessing = false;
    let pendingImage = null;
    let isUserWantsToListen = false;
    let isSpeechSuppressed = false;

    // --- Visitor Recognition ---
    let visitorToken = localStorage.getItem('maggie_visitor_token') || null;

    // Detect Widget Mode
    const urlParams = new URLSearchParams(window.location.search);
    if (urlParams.has('widget') || window.self !== window.top) {
      document.body.classList.add('is-widget');
      console.log('[MAGGIE] Widget mode active.');
    }
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // STATUS POLLING
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    async function updateStatus() {
      try {
        const res = await fetch(`${API}/status`);
        const data = await res.json();

        document.getElementById('exp-val').textContent = data.experience_count || 0;
        document.getElementById('dom-val').textContent = data.domain_count || 0;

        // Context gauge
        const pct = data.context_cap
          ? Math.round((data.stream_tokens / data.context_cap) * 100)
          : 0;
        document.getElementById('ctx-pct').textContent = pct + '%';
        const fill = document.getElementById('ctx-fill');
        fill.style.width = pct + '%';
        fill.className = 'gauge-fill' + (pct > 70 ? ' warning' : '');

        // Sifter reports
        if (data.sifter_patterns && data.sifter_patterns.length > 0) {
          document.getElementById('reports').innerHTML = data.sifter_patterns
            .map(p => `<div class="report-item">${escapeHtml(p.content)}</div>`)
            .join('');
        }

        // Intake feed
        if (data.recent_experiences && data.recent_experiences.length > 0) {
          document.getElementById('activity').innerHTML = data.recent_experiences
            .map(e => {
              const ts = e.timestamp ? e.timestamp.split(' ')[1] || '' : '';
              return `<div class="activity-line"><span class="ts">${ts}</span> ${escapeHtml(e.content)}</div>`;
            }).join('');
        }

        // Graph memory
        document.getElementById('graph-nodes-val').textContent = data.graph_nodes || 0;
        document.getElementById('graph-edges-val').textContent = data.graph_edges || 0;

        if (data.graph_top_nodes && data.graph_top_nodes.length > 0) {
          document.getElementById('graph-empty').style.display = 'none';
          document.getElementById('graph-nodes-display').innerHTML = data.graph_top_nodes
            .map(n => `<span class="graph-node-tag">${escapeHtml(n.label)} <span class="strength">${n.strength}</span></span>`)
            .join('');
        } else {
          document.getElementById('graph-empty').style.display = 'block';
          document.getElementById('graph-nodes-display').innerHTML = '';
        }

        if (data.graph_recent_edges && data.graph_recent_edges.length > 0) {
          document.getElementById('graph-edges-display').innerHTML = data.graph_recent_edges
            .map(e => `<div class="graph-edge">${escapeHtml(e.source_label)} <span class="rel">â€”[${escapeHtml(e.relationship)}]â†’</span> ${escapeHtml(e.target_label)}</div>`)
            .join('');
        } else {
          document.getElementById('graph-edges-display').innerHTML = '';
        }
        // Task tracker
        if (data.tasks_pending !== undefined) {
          document.getElementById('task-stats').innerHTML =
            `Pending: <span>${data.tasks_pending}</span> Â· Done: <span>${data.tasks_done}</span>`;
        }
        if (data.tasks_recent && data.tasks_recent.length > 0) {
          document.getElementById('task-list').innerHTML = data.tasks_recent
            .map(t => {
              const isDone = t.status === 'done';
              return `<div class="task-item${isDone ? ' done' : ''}">
                <span class="task-badge ${isDone ? 'complete' : 'pending'}">${isDone ? 'âœ“' : '#' + t.id}</span>
                ${escapeHtml(t.description)}
              </div>`;
            }).join('');
        }
      } catch {
        document.querySelector('.header-label').innerHTML =
          'PROTOCOL: <span style="color: #ff0e59">LINK LOST</span>';
      }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // SEND MESSAGE
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    function handleImageSelect(event) {
      const file = event.target.files[0];
      if (!file) return;

      const reader = new FileReader();
      reader.onload = (e) => {
        pendingImage = e.target.result; // data:image/...;base64,...
        document.getElementById('image-preview-container').innerHTML =
          `<img src="${pendingImage}" class="image-preview"> <button onclick="clearImage()" style="background:none;border:none;color:var(--neon-orange);cursor:pointer;font-size:0.8rem;">âœ• Remove</button>`;
      };
      reader.readAsDataURL(file);
    }

    function clearImage() {
      pendingImage = null;
      document.getElementById('image-preview-container').innerHTML = '';
      document.getElementById('image-upload').value = '';
    }

    async function handleSend() {
      const input = document.getElementById('user-input');
      const text = input.value.trim();
      if ((!text && !pendingImage) || isProcessing) return;

      isProcessing = true;
      document.getElementById('send-btn').disabled = true;

      // Pause mic while processing
      pauseMicForTTS();

      input.value = '';

      // Show user message
      const displayText = pendingImage ? `ğŸ“· ${text || 'What do you see?'}` : text;
      addMessage(displayText, 'user');

      // Show image preview in chat if attached
      if (pendingImage) {
        const container = document.getElementById('chat-container');
        const imgDiv = document.createElement('div');
        imgDiv.className = 'message user';
        imgDiv.innerHTML = `<img src="${pendingImage}" style="max-width:300px;border-radius:8px;">`;
        container.appendChild(imgDiv);
        container.scrollTop = container.scrollHeight;
      }

      document.getElementById('footer-status').textContent = pendingImage ? 'Analyzing image...' : 'Thinking...';

      // Typing indicator
      const thinkingId = 'ai-thinking-' + Date.now();
      addTyping(thinkingId);

      try {
        const headers = { 'Content-Type': 'application/json' };
        if (visitorToken) headers['x-visitor-token'] = visitorToken;

        let data;
        if (pendingImage) {
          const res = await fetch(`${API}/vision`, {
            method: 'POST',
            headers: headers,
            body: JSON.stringify({ image: pendingImage, message: text || 'What do you see?' })
          });
          data = await res.json();
          clearImage();
        } else {
          const res = await fetch(`${API}/chat`, {
            method: 'POST',
            headers: headers,
            body: JSON.stringify({ message: text })
          });
          data = await res.json();
        }

        removeElement(thinkingId);
        addMessage(data.reply || data.error || 'No signal.', 'ai');
        updateStatus();
      } catch (err) {
        removeElement(thinkingId);
        addMessage(`âš  Error: ${err.message}`, 'ai');
      } finally {
        isProcessing = false;
        document.getElementById('send-btn').disabled = false;
        document.getElementById('footer-status').textContent = 'Ready';
        input.focus();

        // Resume mic after processing (TTS speakText handles its own resume)
        if (!isSpeaking) {
          resumeMicIfNeeded();
        }
      }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // MESSAGE RENDERING
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    function addMessage(text, role) {
      const container = document.getElementById('chat-container');
      const div = document.createElement('div');
      div.className = `message ${role}`;
      div.innerHTML = role === 'ai' ? marked.parse(text) : escapeHtml(text);
      container.appendChild(div);
      container.scrollTop = container.scrollHeight;

      // TTS: Speak if it's AI, not muted, and not an error
      if (role === 'ai' && isTTSActive && !text.includes('âš  Error')) {
        speakText(text);
      }
    }

    function addTyping(id) {
      const container = document.getElementById('chat-container');
      const div = document.createElement('div');
      div.className = 'message ai';
      div.id = id;
      div.innerHTML = '<div class="typing-dots"><span></span><span></span><span></span></div>';
      container.appendChild(div);
      container.scrollTop = container.scrollHeight;
    }

    function removeElement(id) {
      const el = document.getElementById(id);
      if (el) el.remove();
    }

    function escapeHtml(text) {
      const div = document.createElement('div');
      div.textContent = text;
      return div.innerHTML;
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // HISTORY & ACTIONS
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    async function loadHistory() {
      try {
        const res = await fetch(`${API}/history`);
        const data = await res.json();
        if (data && data.history && data.history.length > 0) {
          const container = document.getElementById('chat-container');
          container.innerHTML = '';
          data.history.forEach(m => {
            if (m.role !== 'system') {
              addMessage(m.content, m.role === 'user' ? 'user' : 'ai');
            }
          });
        }
      } catch { /* first load */ }
    }



    async function copyHistory() {
      const msgs = Array.from(document.querySelectorAll('.message'))
        .filter(m => !m.classList.contains('system-note'))
        .map(m => (m.classList.contains('user') ? 'JEWELLS: ' : ': ') + m.innerText)
        .join('\n\n');
      await navigator.clipboard.writeText(msgs);
      alert('Memory log synchronized to clipboard.');
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // KEYBOARD
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    document.getElementById('user-input').addEventListener('keypress', (e) => {
      if (e.key === 'Enter') handleSend();
    });

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // TEXT-TO-SPEECH (TTS) â€” Clean Web Speech API
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    let isTTSActive = true;
    let isSpeaking = false;
    let selectedVoice = null;

    // Pre-load voices (Chrome loads them async)
    function loadVoices() {
      const voices = window.speechSynthesis.getVoices();
      if (voices.length === 0) return;
      // Pick best voice: Zira > Google UK English Female > any Female > en-US fallback
      selectedVoice =
        voices.find(v => v.name.includes('Zira')) ||
        voices.find(v => v.name.includes('Google UK English Female')) ||
        voices.find(v => v.name.toLowerCase().includes('female') && v.lang.startsWith('en')) ||
        voices.find(v => v.lang === 'en-US') ||
        voices[0];
      console.log('[TTS] Voice selected:', selectedVoice?.name || 'default');
    }
    // Chrome fires onvoiceschanged, Firefox/Edge may have them ready immediately
    if (window.speechSynthesis) {
      loadVoices();
      window.speechSynthesis.onvoiceschanged = loadVoices;
    }

    function toggleTTS() {
      isTTSActive = !isTTSActive;
      const btn = document.getElementById('tts-toggle');
      if (isTTSActive) {
        btn.textContent = 'ğŸ”ˆ ON';
        btn.style.opacity = '1';
      } else {
        btn.textContent = 'ğŸ”‡ OFF';
        btn.style.opacity = '0.5';
        window.speechSynthesis.cancel();
        isSpeaking = false;
        resumeMicIfNeeded();
      }
    }

    function cleanTextForSpeech(text) {
      let clean = text;
      clean = clean.replace(/```[\s\S]*?```/g, ' code block ');
      clean = clean.replace(/`([^`]+)`/g, '$1');
      clean = clean.replace(/\[([^\]]+)\]\([^\)]+\)/g, '$1');
      clean = clean.replace(/[\*\_]{1,3}([^\*\_]+)[\*\_]{1,3}/g, '$1');
      clean = clean.replace(/#{1,6}\s*/g, '');
      clean = clean.replace(/[->\+\|]/g, '');
      clean = clean.replace(/\n{2,}/g, '. ');
      clean = clean.replace(/\s{2,}/g, ' ');
      return clean.trim();
    }

    async function speakText(text) {
      if (!isTTSActive) return;

      // Widget mode: delegate to parent window
      if (window.parent !== window) {
        window.parent.postMessage({ type: 'MAGGIE_SPEAK', text }, '*');
        return;
      }

      const synth = window.speechSynthesis;
      if (!synth) return;

      // Pause mic while MAGGIE speaks
      pauseMicForTTS();

      synth.cancel();
      isSpeaking = true;

      const clean = cleanTextForSpeech(text);
      if (!clean) { isSpeaking = false; resumeMicIfNeeded(); return; }

      // Split into sentences for reliable playback (Chrome has a ~15s utterance limit)
      const chunks = clean.match(/[^.!?]+[.!?]*/g) || [clean];

      for (const chunk of chunks) {
        if (!isTTSActive || !isSpeaking) break;
        const trimmed = chunk.trim();
        if (!trimmed) continue;

        await new Promise((resolve) => {
          const utterance = new SpeechSynthesisUtterance(trimmed);
          if (selectedVoice) utterance.voice = selectedVoice;
          utterance.rate = 1.05;
          utterance.pitch = 1.05;
          utterance.onend = resolve;
          utterance.onerror = () => resolve();

          // Chrome bug workaround: long utterances silently stop
          // Keep-alive by pausing/resuming every 10s
          let keepAlive = null;
          if (trimmed.length > 100) {
            keepAlive = setInterval(() => {
              if (synth.speaking && !synth.paused) {
                synth.pause();
                synth.resume();
              }
            }, 10000);
          }
          utterance.addEventListener('end', () => clearInterval(keepAlive));
          utterance.addEventListener('error', () => clearInterval(keepAlive));

          synth.speak(utterance);
        });
      }

      isSpeaking = false;
      resumeMicIfNeeded();
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // SPEECH-TO-TEXT (STT) â€” Mic Input
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    let recognition = null;
    let isBrowserListening = false;

    function initSpeech() {
      const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SR) {
        const micBtn = document.getElementById('mic-btn');
        if (micBtn) {
          micBtn.title = 'Speech not supported â€” use Chrome or Edge';
          micBtn.style.opacity = '0.3';
          micBtn.onclick = () => alert('Speech recognition requires Chrome or Edge.');
        }
        console.warn('[STT] SpeechRecognition API not available.');
        return;
      }

      recognition = new SR();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'en-US';

      recognition.onstart = () => {
        isBrowserListening = true;
        document.getElementById('mic-btn')?.classList.add('recording');
        const s = document.getElementById('footer-status');
        if (s) s.textContent = 'Listening...';
        console.log('[STT] Mic active.');
      };

      recognition.onresult = (event) => {
        let transcript = '';
        for (let i = event.resultIndex; i < event.results.length; i++) {
          transcript += event.results[i][0].transcript;
        }
        const input = document.getElementById('user-input');
        if (input) input.value = transcript;
      };

      recognition.onerror = (event) => {
        console.error('[STT] Error:', event.error);
        // Only alert on permission denial, not transient errors
        if (event.error === 'not-allowed' || event.error === 'service-not-allowed') {
          alert('Microphone access denied. Please allow mic access in your browser settings.');
        }
        // aborted errors are expected during TTS suppression â€” ignore
        if (event.error !== 'aborted' && event.error !== 'no-speech') {
          stopRecording();
        }
      };

      recognition.onend = () => {
        isBrowserListening = false;
        document.getElementById('mic-btn')?.classList.remove('recording');
        const s = document.getElementById('footer-status');
        if (s && !isSpeaking) s.textContent = 'Ready';

        // Auto-restart if user wants to keep listening and we're not in TTS
        if (isUserWantsToListen && !isSpeechSuppressed && !isSpeaking) {
          try { recognition.start(); } catch (e) { /* already running or destroyed */ }
        }
      };
    }

    function toggleMic() {
      if (!recognition) initSpeech();
      if (!recognition) return;

      if (isBrowserListening) {
        // User is turning OFF the mic
        isUserWantsToListen = false;
        isSpeechSuppressed = false;
        stopRecording();
      } else {
        // User is turning ON the mic
        isUserWantsToListen = true;
        isSpeechSuppressed = false;
        try {
          recognition.start();
        } catch (e) {
          console.error('[STT] Start failed:', e);
          // If already started, stop and restart
          try { recognition.stop(); } catch (_) { }
          setTimeout(() => {
            try { recognition.start(); } catch (_) { }
          }, 200);
        }
      }
    }

    function stopRecording() {
      if (recognition) {
        try { recognition.stop(); } catch (e) { }
      }
      isBrowserListening = false;
      document.getElementById('mic-btn')?.classList.remove('recording');
    }

    // --- Mic â†” TTS coordination ---
    function pauseMicForTTS() {
      isSpeechSuppressed = true;
      if (isBrowserListening && recognition) {
        try { recognition.abort(); } catch (e) { }
      }
    }

    function resumeMicIfNeeded() {
      isSpeechSuppressed = false;
      if (isUserWantsToListen && !isBrowserListening && recognition) {
        setTimeout(() => {
          try { recognition.start(); } catch (e) { }
        }, 300);
      }
    }


    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // EMAIL COLLECTION
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    async function submitEmail() {
      // Find the active container (either the sidebar or the metrics overlay)
      const overlay = document.getElementById('metrics-overlay');
      const container = (overlay && overlay.classList.contains('active')) ? overlay : document.body;

      const nameInput = container.querySelector('#collect-name');
      const emailInput = container.querySelector('#collect-email');
      const status = container.querySelector('#collect-status');

      const name = nameInput ? nameInput.value : '';
      const email = emailInput ? emailInput.value : '';

      if (!email || !email.includes('@')) {
        status.textContent = 'Please provide a valid email.';
        statusElement.textContent = 'Please enter a valid email.';
        return;
      }

      statusElement.textContent = 'Connecting with identity core...';

      try {
        // 1. Register with MAGGIE's Backend (MySQL)
        const regRes = await fetch(`${API}/register`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ name, email })
        });
        const regData = await regRes.json();

        if (regData.token) {
          visitorToken = regData.token;
          localStorage.setItem('maggie_visitor_token', visitorToken);
          console.log('[Visitor] Registered and token saved.');
        }

        // 2. Sync with Google Sheets (Existing logic)
        const scriptURL = 'https://script.google.com/macros/s/AKfycbyv9O9f-pX-LID_mH87H33IExSInV_U9V67_K68n3F4m8R8F-Q8R8F-X4m8R8F-Q/exec';
        await fetch(scriptURL, {
          method: 'POST',
          body: new FormData(document.getElementById('contact-form')),
          mode: 'no-cors'
        });

        statusElement.textContent = regData.isReturning ?
          `Welcome back, ${regData.name}! She remembers you.` :
          'Registration complete. She knows who you are now.';

        statusElement.style.color = '#00ffcc';

        setTimeout(() => {
          toggleContact();
          // Ask MAGGIE to greet the new user if new
          if (!regData.isReturning) {
            addMessage(`(A new friend has joined: ${name})`, 'user');
            handleSend();
          }
        }, 2000);

      } catch (error) {
        console.error('Submission failed', error);
        statusElement.textContent = 'Connection failed. Please try again.';
        statusElement.style.color = '#ff4b2b';
      }
    }

    async function checkVisitorIdentity() {
      if (!visitorToken) return;
      try {
        const res = await fetch(`${API}/whoami`, {
          headers: { 'x-visitor-token': visitorToken }
        });
        const data = await res.json();
        if (data.recognized) {
          console.log(`[Visitor] Recognized as ${data.name}`);
          // Optional: Add a subtle hint in UI that she knows you
          document.getElementById('footer-status').textContent = `Recognized: ${data.name}`;
        } else {
          // Token invalid or burned? Clean up.
          visitorToken = null;
          localStorage.removeItem('maggie_visitor_token');
        }
      } catch (err) {
        console.error('[Visitor Check Error]', err);
      }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // WIDGET METRICS TOGGLE
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    function toggleMetrics() {
      const overlay = document.getElementById('metrics-overlay');
      const isVisible = overlay.classList.toggle('active');

      if (isVisible) {
        // Refresh metrics content immediately
        const metrics = document.querySelector('.sidebar .metric-card').cloneNode(true);
        const gauge = document.querySelector('.sidebar .context-gauge').cloneNode(true);

        // Find the email collect card
        const emailCard = document.querySelector('.email-collect-card').parentElement.cloneNode(true);

        const content = document.getElementById('metrics-content');
        content.innerHTML = '';
        content.appendChild(metrics);
        content.appendChild(gauge);
        content.appendChild(emailCard);

        // Re-wire the button in the clone
        const cloneBtn = content.querySelector('button');
        if (cloneBtn) {
          cloneBtn.onclick = submitEmail;
        }
      }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // INIT
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    async function init() {
      // First, check if we recognize the user
      await checkVisitorIdentity();

      // Update status immediately
      updateStatus();

      // Load chat history
      loadHistory();

      // Initialize speech
      initSpeech();

      // Polling for metrics
      setInterval(updateStatus, 30000); // Poll every 30s

      // Refresh stats every 5 minutes to stay current
      setInterval(updateStatus, 300000);
    }

    // Start
    init();
  </script>
</body>

</html>