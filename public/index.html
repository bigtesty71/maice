<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>MAIce | Mistral AI companion Experiment</title>
  <meta name="description" content="MAIce â€” Mistral AI companion Experiment with MemoryKeep graph memory.">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Outfit:wght@300;400;600;700&family=JetBrains+Mono:wght@400;500&display=swap"
    rel="stylesheet">
  <link rel="stylesheet" href="index.css">
  <script src="https://js.puter.com/v2/"></script>
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
</head>

<body>

  <!-- â•â•â• SIDEBAR â•â•â• -->
  <div class="sidebar">
    <div class="logo">
      <span class="icon">âš¡</span> MAIce
    </div>

    <div class="sidebar-body">
      <!-- Neural Metrics -->
      <div class="widget">
        <div class="widget-title">Neural Metrics</div>
        <div class="metric-card">
          <div class="metric-mini">
            <div id="exp-val" class="metric-value">0</div>
            <div class="metric-label">Experiences</div>
          </div>
          <div class="metric-mini">
            <div id="dom-val" class="metric-value">0</div>
            <div class="metric-label">Domain</div>
          </div>
          <div class="metric-mini">
            <div id="graph-nodes-val" class="metric-value" style="color: var(--neon-cyan)">0</div>
            <div class="metric-label">Nodes</div>
          </div>
          <div class="metric-mini">
            <div id="graph-edges-val" class="metric-value" style="color: var(--neon-orange)">0</div>
            <div class="metric-label">Edges</div>
          </div>
        </div>

        <!-- Context Gauge -->
        <div class="context-gauge">
          <div class="gauge-header">
            <span class="gauge-label">Stream Context</span>
            <span class="gauge-value" id="ctx-pct">0%</span>
          </div>
          <div class="gauge-bar">
            <div class="gauge-fill" id="ctx-fill" style="width: 0%"></div>
          </div>
        </div>
      </div>

      <!-- Sifter Reports -->
      <div class="widget">
        <div class="widget-title">Sleep Cycle Reports (The Sifter)</div>
        <div class="report-card" id="reports">
          <div class="report-empty">Awaiting first sleep simulation...</div>
        </div>
      </div>

      <!-- Intake Valve -->
      <div class="widget">
        <div class="widget-title">Intake Valve (Live)</div>
        <div id="activity" class="activity-feed">
          <div class="activity-line">Core protocols loaded.</div>
        </div>
      </div>

      <!-- Knowledge Graph -->
      <div class="widget">
        <div class="widget-title">Knowledge Graph</div>
        <div class="graph-panel" id="graph-panel">
          <div id="graph-nodes-display" class="graph-node-list"></div>
          <div id="graph-edges-display"></div>
          <div class="graph-empty" id="graph-empty">Graph builds as you talk...</div>
        </div>
      </div>

      <!-- Task Tracker -->
      <div class="widget">
        <div class="widget-title">Task Tracker</div>
        <div class="task-stats" id="task-stats"></div>
        <div class="task-list" id="task-list">
          <div class="task-empty">No tasks yet. Ask MAIce to create one.</div>
        </div>
      </div>
    </div>

    <div class="sidebar-footer">
      USER: JEWELLS | <span class="neural-pulse"></span>SESSION STABLE
    </div>
  </div>

  <!-- â•â•â• MAIN CONTENT â•â•â• -->
  <div class="main-content">
    <div class="header">
      <div class="header-label">
        PROTOCOL: <span class="active">NEURAL-KEEP (AGENTIC)</span> Â· MAIce ENGINE
      </div>
      <div class="header-actions">
        <button id="tts-toggle" onclick="toggleTTS()" class="action-btn" title="Toggle Voice">ğŸ”ˆ ON</button>
        <button onclick="copyHistory()" class="action-btn">COPY LOGS</button>
        <button onclick="resetBrain()" class="action-btn danger">RESET</button>
      </div>
    </div>

    <div id="chat-container">
      <div class="message system-note">MAIce Neural Bridge Connected. MemoryKeep v3 + Graph + Vision + Email + Browser +
        Telegram Active. 11 agentic tools online. Heartbeat engaged.</div>
    </div>

    <div class="input-wrapper">
      <div class="input-container">
        <input id="image-upload" type="file" accept="image/*" style="display:none" onchange="handleImageSelect(event)">
        <button class="upload-btn" onclick="document.getElementById('image-upload').click()"
          title="Upload image for vision">ğŸ“·</button>
        <button id="mic-btn" class="mic-btn" onclick="toggleMic()" title="Speech-to-text">ğŸ™ï¸</button>
        <input id="user-input" type="text" placeholder="Transceive input..." autocomplete="off">
        <button id="send-btn" onclick="handleSend()" class="send-btn">SEND</button>
      </div>
      <div id="image-preview-container" style="padding: 0 4px;"></div>
      <div class="input-footer">
        <span>MAIce Â· Mistral AI companion Experiment</span>
        <span id="footer-status">Ready</span>
      </div>
    </div>
  </div>

  <script>
    const API = '';
    let isProcessing = false;

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // STATUS POLLING
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    async function updateStatus() {
      try {
        const res = await fetch(`${API}/status`);
        const data = await res.json();

        document.getElementById('exp-val').textContent = data.experience_count || 0;
        document.getElementById('dom-val').textContent = data.domain_count || 0;

        // Context gauge
        const pct = data.context_cap
          ? Math.round((data.stream_tokens / data.context_cap) * 100)
          : 0;
        document.getElementById('ctx-pct').textContent = pct + '%';
        const fill = document.getElementById('ctx-fill');
        fill.style.width = pct + '%';
        fill.className = 'gauge-fill' + (pct > 70 ? ' warning' : '');

        // Sifter reports
        if (data.sifter_patterns && data.sifter_patterns.length > 0) {
          document.getElementById('reports').innerHTML = data.sifter_patterns
            .map(p => `<div class="report-item">${escapeHtml(p.content)}</div>`)
            .join('');
        }

        // Intake feed
        if (data.recent_experiences && data.recent_experiences.length > 0) {
          document.getElementById('activity').innerHTML = data.recent_experiences
            .map(e => {
              const ts = e.timestamp ? e.timestamp.split(' ')[1] || '' : '';
              return `<div class="activity-line"><span class="ts">${ts}</span> ${escapeHtml(e.content)}</div>`;
            }).join('');
        }

        // Graph memory
        document.getElementById('graph-nodes-val').textContent = data.graph_nodes || 0;
        document.getElementById('graph-edges-val').textContent = data.graph_edges || 0;

        if (data.graph_top_nodes && data.graph_top_nodes.length > 0) {
          document.getElementById('graph-empty').style.display = 'none';
          document.getElementById('graph-nodes-display').innerHTML = data.graph_top_nodes
            .map(n => `<span class="graph-node-tag">${escapeHtml(n.label)} <span class="strength">${n.strength}</span></span>`)
            .join('');
        } else {
          document.getElementById('graph-empty').style.display = 'block';
          document.getElementById('graph-nodes-display').innerHTML = '';
        }

        if (data.graph_recent_edges && data.graph_recent_edges.length > 0) {
          document.getElementById('graph-edges-display').innerHTML = data.graph_recent_edges
            .map(e => `<div class="graph-edge">${escapeHtml(e.source_label)} <span class="rel">â€”[${escapeHtml(e.relationship)}]â†’</span> ${escapeHtml(e.target_label)}</div>`)
            .join('');
        } else {
          document.getElementById('graph-edges-display').innerHTML = '';
        }
        // Task tracker
        if (data.tasks_pending !== undefined) {
          document.getElementById('task-stats').innerHTML =
            `Pending: <span>${data.tasks_pending}</span> Â· Done: <span>${data.tasks_done}</span>`;
        }
        if (data.tasks_recent && data.tasks_recent.length > 0) {
          document.getElementById('task-list').innerHTML = data.tasks_recent
            .map(t => {
              const isDone = t.status === 'done';
              return `<div class="task-item${isDone ? ' done' : ''}">
                <span class="task-badge ${isDone ? 'complete' : 'pending'}">${isDone ? 'âœ“' : '#' + t.id}</span>
                ${escapeHtml(t.description)}
              </div>`;
            }).join('');
        }
      } catch {
        document.querySelector('.header-label').innerHTML =
          'PROTOCOL: <span style="color: #ff0e59">LINK LOST</span>';
      }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // SEND MESSAGE
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    let pendingImage = null;

    function handleImageSelect(event) {
      const file = event.target.files[0];
      if (!file) return;

      const reader = new FileReader();
      reader.onload = (e) => {
        pendingImage = e.target.result; // data:image/...;base64,...
        document.getElementById('image-preview-container').innerHTML =
          `<img src="${pendingImage}" class="image-preview"> <button onclick="clearImage()" style="background:none;border:none;color:var(--neon-orange);cursor:pointer;font-size:0.8rem;">âœ• Remove</button>`;
      };
      reader.readAsDataURL(file);
    }

    function clearImage() {
      pendingImage = null;
      document.getElementById('image-preview-container').innerHTML = '';
      document.getElementById('image-upload').value = '';
    }

    async function handleSend() {
      const input = document.getElementById('user-input');
      const text = input.value.trim();
      if ((!text && !pendingImage) || isProcessing) return;

      isProcessing = true;
      document.getElementById('send-btn').disabled = true;
      input.value = '';

      // Show user message
      const displayText = pendingImage ? `ğŸ“· ${text || 'What do you see?'}` : text;
      addMessage(displayText, 'user');

      // Show image preview in chat if attached
      if (pendingImage) {
        const container = document.getElementById('chat-container');
        const imgDiv = document.createElement('div');
        imgDiv.className = 'message user';
        imgDiv.innerHTML = `<img src="${pendingImage}" style="max-width:300px;border-radius:8px;">`;
        container.appendChild(imgDiv);
        container.scrollTop = container.scrollHeight;
      }

      document.getElementById('footer-status').textContent = pendingImage ? 'Analyzing image...' : 'Thinking...';

      // Typing indicator
      const thinkingId = 'ai-thinking-' + Date.now();
      addTyping(thinkingId);

      try {
        let data;
        if (pendingImage) {
          // Vision endpoint
          const res = await fetch(`${API}/vision`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ image: pendingImage, message: text || 'What do you see in this image?' })
          });
          data = await res.json();
          clearImage();
        } else {
          // Normal chat endpoint
          const res = await fetch(`${API}/chat`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ message: text })
          });
          data = await res.json();
        }

        removeElement(thinkingId);
        addMessage(data.reply || data.error || 'No signal received.', 'ai');
        updateStatus();
      } catch (err) {
        removeElement(thinkingId);
        addMessage(`âš  Connection error: ${err.message}`, 'ai');
      }

      isProcessing = false;
      document.getElementById('send-btn').disabled = false;
      document.getElementById('footer-status').textContent = 'Ready';
      input.focus();

      // If continuous speech was active, restart it to clear the session buffer
      // (Otherwise previous text keeps re-appearing)
      if (isRecording && recognition) {
        recognition.abort(); // Stop listening
        setTimeout(() => {
          try {
            recognition.start(); // Restart fresh
            document.getElementById('footer-status').textContent = 'Listening... (Click mic to stop)';
          } catch (e) { console.error('Restart speech failed', e); }
        }, 300);
      }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // MESSAGE RENDERING
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    function addMessage(text, role) {
      const container = document.getElementById('chat-container');
      const div = document.createElement('div');
      div.className = `message ${role}`;
      div.innerHTML = role === 'ai' ? marked.parse(text) : escapeHtml(text);
      container.appendChild(div);
      container.scrollTop = container.scrollHeight;

      // TTS: Speak if it's AI and not muted
      if (role === 'ai' && isTTSActive) {
        speakText(text);
      }
    }

    function addTyping(id) {
      const container = document.getElementById('chat-container');
      const div = document.createElement('div');
      div.className = 'message ai';
      div.id = id;
      div.innerHTML = '<div class="typing-dots"><span></span><span></span><span></span></div>';
      container.appendChild(div);
      container.scrollTop = container.scrollHeight;
    }

    function removeElement(id) {
      const el = document.getElementById(id);
      if (el) el.remove();
    }

    function escapeHtml(text) {
      const div = document.createElement('div');
      div.textContent = text;
      return div.innerHTML;
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // HISTORY & ACTIONS
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    async function loadHistory() {
      try {
        const res = await fetch(`${API}/history`);
        const data = await res.json();
        if (data && data.history && data.history.length > 0) {
          const container = document.getElementById('chat-container');
          container.innerHTML = '';
          data.history.forEach(m => {
            if (m.role !== 'system') {
              addMessage(m.content, m.role === 'user' ? 'user' : 'ai');
            }
          });
        }
      } catch { /* first load */ }
    }

    async function resetBrain() {
      if (!confirm('âš  This will wipe all memories. Are you sure?')) return;
      try {
        await fetch(`${API}/reset`, { method: 'POST' });
        document.getElementById('chat-container').innerHTML =
          '<div class="message system-note">Brain wiped. Neural Bridge reconnected.</div>';
        updateStatus();
      } catch (err) {
        alert('Reset failed: ' + err.message);
      }
    }

    async function copyHistory() {
      const msgs = Array.from(document.querySelectorAll('.message'))
        .filter(m => !m.classList.contains('system-note'))
        .map(m => (m.classList.contains('user') ? 'JEWELLS: ' : 'MAIce: ') + m.innerText)
        .join('\n\n');
      await navigator.clipboard.writeText(msgs);
      alert('Memory log synchronized to clipboard.');
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // KEYBOARD
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    document.getElementById('user-input').addEventListener('keypress', (e) => {
      if (e.key === 'Enter') handleSend();
    });

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // TEXT-TO-SPEECH (TTS)
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    let isTTSActive = true;
    let currentAudio = null;

    function toggleTTS() {
      isTTSActive = !isTTSActive;
      const btn = document.getElementById('tts-toggle');
      if (isTTSActive) {
        btn.textContent = 'ğŸ”ˆ ON';
        btn.style.opacity = '1';
      } else {
        btn.textContent = 'ğŸ”‡ OFF';
        btn.style.opacity = '0.5';
        if (currentAudio) {
          currentAudio.pause();
          currentAudio = null;
        }
      }
    }

    async function speakText(markdown) {
      if (!isTTSActive) return;

      // Strip markdown for cleaner speech
      let clean = markdown.replace(/```[\s\S]*?```/g, " [Code Block] ");
      clean = clean.replace(/`([^`]+)`/g, "$1");
      clean = clean.replace(/\[([^\]]+)\]\([^\)]+\)/g, "$1");
      clean = clean.replace(/[\*\_]{1,3}([^\*\_]+)[\*\_]{1,3}/g, "$1");

      try {
        // Stop any currently playing audio
        if (currentAudio) {
          currentAudio.pause();
        }

        console.log('[Puter TTS] Synthesizing...');
        // We use Puter's advanced txt2speech which returns an Audio object
        currentAudio = await puter.ai.txt2speech(clean);
        currentAudio.play();
      } catch (err) {
        console.error('[Puter TTS Error]', err);
        // Fallback to native if Puter fails
        const utterance = new SpeechSynthesisUtterance(clean);
        window.speechSynthesis.speak(utterance);
      }
    }

    // Load voices immediately so they fail gracefully if not ready
    if (synth.onvoiceschanged !== undefined) {
      synth.onvoiceschanged = () => { };
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // SPEECH-TO-TEXT
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    let recognition = null;
    let isRecording = false;

    function initSpeech() {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        const micBtn = document.getElementById('mic-btn');
        micBtn.title = 'Speech not supported in this browser';
        micBtn.style.opacity = '0.3';
        micBtn.onclick = () => alert('Speech recognition is not supported in this browser. Please use Chrome or Edge.');
        return;
      }
      recognition = new SpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'en-US';

      recognition.onresult = (event) => {
        let fullTranscript = '';
        for (let i = 0; i < event.results.length; ++i) {
          fullTranscript += event.results[i][0].transcript;
        }
        document.getElementById('user-input').value = fullTranscript;
      };

      recognition.onerror = (event) => {
        console.error('[STT Error]', event.error);
        if (event.error === 'not-allowed') {
          alert('Microphone access denied. Please enable microphone permissions in your browser settings.');
        } else if (event.error === 'network') {
          alert('Network error during speech recognition. Please check your connection.');
        } else if (event.error !== 'no-speech') {
          console.warn('[STT] Recognition error:', event.error);
        }
        stopRecording();
      };

      recognition.onend = () => {
        if (isRecording) {
          // Unexpected stop, try to restart if it wasn't a manual stop
          console.log('[STT] Recognition ended unexpectedly, attempting restart...');
          try {
            recognition.start();
          } catch (e) {
            stopRecording();
          }
        }
      };
    }

    function toggleMic() {
      if (!recognition) {
        initSpeech();
        if (!recognition) return;
      }

      const input = document.getElementById('user-input');
      const micBtn = document.getElementById('mic-btn');
      const footerStatus = document.getElementById('footer-status');

      if (isRecording) {
        isRecording = false; // Set state first
        try {
          recognition.stop();
        } catch (e) {
          console.warn('[STT] Stop failed:', e);
        }
        stopRecording();
      } else {
        try {
          // Double check to avoid InvalidStateError if it was somehow already running
          try { recognition.abort(); } catch (e) { }

          input.value = '';
          recognition.start();
          isRecording = true;
          micBtn.classList.add('recording');
          footerStatus.textContent = 'Listening... (Click mic to stop)';
          console.log('[STT] Recording started.');
        } catch (err) {
          console.error('[STT Start Error]', err);
          // If it's already started, just sync our local state
          if (err.name === 'InvalidStateError') {
            isRecording = true;
            micBtn.classList.add('recording');
            footerStatus.textContent = 'Listening... (Click mic to stop)';
          } else {
            alert('Microphone error: ' + err.message);
            stopRecording();
          }
        }
      }
    }

    function stopRecording() {
      isRecording = false;
      const micBtn = document.getElementById('mic-btn');
      const footerStatus = document.getElementById('footer-status');
      if (micBtn) micBtn.classList.remove('recording');
      if (footerStatus && footerStatus.textContent.includes('Listening')) {
        footerStatus.textContent = 'Ready';
      }
      console.log('[STT] Recording stopped.');
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // INIT
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    updateStatus();
    loadHistory();
    initSpeech();
    setInterval(updateStatus, 30000);
  </script>
</body>

</html>